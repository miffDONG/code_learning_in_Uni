{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jED6HIR_6tzp"
      },
      "source": [
        "# Homework 3. Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLDUA1CdJ9Tu",
        "outputId": "2f443a3b-bd5d-48fc-aa00-d2d9c8d8877b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmxY_27i6tzq"
      },
      "source": [
        "***Double Click here to edit this cell***\n",
        "\n",
        "- Name: 김현동\n",
        "- Student ID: 201901208\n",
        "- Submission date: 2023-05-05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heluMSZO6tzq"
      },
      "source": [
        "# You must run this homework code on Google Colab\n",
        "\n",
        "- DON'T run on Google Colab Pro\n",
        "- DON'T use GPU or TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9doWdXr6tzr"
      },
      "source": [
        "### You must run the following two cells to make sure you are running on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djulUzix6tzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b560e00c-dedd-4024-edd9-315b76c22090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05k-pGgd6tzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e09f54-6eee-4ab3-b0f8-46141974408e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13297192 kB\n",
            "MemFree:         9556560 kB\n",
            "MemAvailable:   12321440 kB\n",
            "Buffers:          381820 kB\n",
            "Cached:          2546160 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           786796 kB\n",
            "Inactive:        2719912 kB\n",
            "Active(anon):       4696 kB\n",
            "Inactive(anon):   562700 kB\n",
            "Active(file):     782100 kB\n",
            "Inactive(file):  2157212 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              1260 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        572432 kB\n",
            "Mapped:           319168 kB\n",
            "Shmem:              7764 kB\n",
            "KReclaimable:     134036 kB\n",
            "Slab:             166600 kB\n",
            "SReclaimable:     134036 kB\n",
            "SUnreclaim:        32564 kB\n",
            "KernelStack:        5408 kB\n",
            "PageTables:         8284 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648596 kB\n",
            "Committed_AS:    3259960 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       10292 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1320 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:     18432 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      138040 kB\n",
            "DirectMap2M:     7198720 kB\n",
            "DirectMap1G:     8388608 kB\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGpIbvhN6tzr"
      },
      "source": [
        "## Remark: gradient_descent.py, linear_algebra.py must be in the folder having this notebook file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7S76uan6tzs"
      },
      "outputs": [],
      "source": [
        "# run this cell\n",
        "from gradient_descent import *\n",
        "from linear_algebra import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YeL1HIs6tzs"
      },
      "source": [
        "## Problem 1 (5 pts)\n",
        "\n",
        "- The following function has a minimum at $(2, 3)$\n",
        "$$\n",
        "f(x_1, x_2) = (x_1 - 2)^2 + (x_2 - 3)^2\n",
        "$$\n",
        "\n",
        "- We want to compute the minimum of $f$ using the gradient descent algorithm\n",
        "- Define a function (```f```) and gradient of function (```f_gradient```)\n",
        "- **Do NOT use numpy functions to define f and f_gradient**\n",
        "- **USE functions in linear_algebra.py**\n",
        "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZq4JQ1B6tzs"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "def f(theta):\n",
        "  return (theta[0]-2)**2+(theta[1]-3)**2\n",
        "\n",
        "def f_gradient(theta):\n",
        "  return [2*(theta[0]-2),2*(theta[1]-3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blFRgkFD6tzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8a405e-0940-4473-979e-6d453fced7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 543 µs, sys: 105 µs, total: 648 µs\n",
            "Wall time: 656 µs\n",
            "solution is [1.997524119921429, 2.996286179882144]\n",
            "++++++++++ Problem 1 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "init_x = [0.,0.]\n",
        "%time solution = minimize_batch(f, f_gradient, init_x, tolerance=0.00001)\n",
        "\n",
        "### correctness check\n",
        "print('solution is {}'.format(solution))\n",
        "EPSILON = 0.01\n",
        "cond1 = math.fabs(solution[0] - 2.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 3.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 1 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 1 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyirB9Ub6tzs"
      },
      "source": [
        "## Problem 2 (10 pts)\n",
        "\n",
        "- The centroid of a finite set of $\\displaystyle {k}$ points $\\displaystyle \\mathbf {x} _{1},\\mathbf {x} _{2},\\ldots ,\\mathbf {x} _{k}$ in $\\displaystyle \\mathbb {R} ^{n}$ is\n",
        "$$\n",
        "\\mathbf {C} ={\\frac {\\mathbf {x} _{1}+\\mathbf {x} _{2}+\\cdots +\\mathbf {x} _{k}}{k}}\n",
        "$$\n",
        "\n",
        "- We want to compute a centroid by **minimizing the mean of squared Euclidean distances between itself and each point in the set**\n",
        "$$\n",
        "x_{\\text{centroid}} = \\text{argmin}_{\\text{c}} {\\frac{\\sum_{i=1}^{n}d({\\text{c}}, x_i)^2}{n}}\n",
        "$$\n",
        "- Define a function (```sq_dist```) and gradient of function (```sq_dist_gradient```)\n",
        "- **Do NOT use numpy functions to define sq_dist and sq_dist_gradient**\n",
        "- **USE functions in linear_algebra.py**\n",
        "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMq6LQ8D6tzt"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "\n",
        "def sq_dist(x, X):\n",
        "    return sum(sum_of_squares(vector_subtract(x, v)) for v in X)\n",
        "\n",
        "def sq_dist_gradient(x, X):\n",
        "    return [2 * sum(vector_subtract(x, v)[j] for v in X) for j in range(len(x))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqjeDfv36tzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bbc211-c294-4002-b476-b3c7da794e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 145 ms, sys: 761 µs, total: 146 ms\n",
            "Wall time: 150 ms\n",
            "solution is [99.99902174958545, 700.1426346570702]\n",
            "++++++++++ Problem 2 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + np.random.randn(100,2)\n",
        "\n",
        "f = partial(sq_dist, X=X)\n",
        "gradient_f = partial(sq_dist_gradient, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print('solution is {}'.format(solution))\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 2 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhj-LdTN6tzt"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + np.random.randn(100000,2)     # 100 thousands\n",
        "\n",
        "f = partial(sq_dist, X=X)\n",
        "gradient_f = partial(sq_dist_gradient, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print('solution is {}'.format(solution))\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '+'*10 + ' Problem 2 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 2 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLkojIDK6tzt"
      },
      "source": [
        "**Time taken in my computer**:\n",
        "```\n",
        "Wall time: 2min 22s\n",
        "solution is [99.99988468682913, 700.0052527466843]\n",
        "++++++++++ Problem 2 check passed ++++++++++\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y3D-8qF6tzt"
      },
      "source": [
        "## Problem 3 (10 pts)\n",
        "\n",
        "- Continued from Problem 2\n",
        "- We want to compute a centroid\n",
        "- Define a function (```sq_dist_numpy```) and gradient of function (```sq_dist_gradient_numpy```)\n",
        "- **Use numpy functions to define sq_dist and sq_dist_gradient**\n",
        "- **Do NOT use functions in linear_algebra.py**\n",
        "### <span style=\"color:red\">**You write two functions. Each function must have ONE line of code in function body; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNzvld1l6tzt"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "import numpy as np\n",
        "\n",
        "def sq_dist_numpy(x, X):\n",
        "    return np.sum(np.square(X - x)).sum()\n",
        "\n",
        "def sq_dist_gradient_numpy(x, X):\n",
        "    return -2 * np.sum(np.subtract(X, x), axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMOZPsEC6tzu"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + np.random.randn(100000,2)\n",
        "\n",
        "f = partial(sq_dist_numpy, X=X)\n",
        "gradient_f = partial(sq_dist_gradient_numpy, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print(solution)\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 3 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 3 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYOfoRPq6tzu"
      },
      "source": [
        "**Time taken in my computer**:\n",
        "```\n",
        "Wall time: 1.49 s\n",
        "[99.99988468682913, 700.0052527466843]\n",
        "++++++++++ Problem 3 check passed ++++++++++\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv_YvnzN6tzu"
      },
      "source": [
        "## Problem 4 (10 pts)\n",
        "\n",
        "- We want to compute a centroid using Manhattan distance\n",
        "- Define a function (```abs_diff_numpy```) and gradient of function (```abs_diff_gradient_numpy```)\n",
        "- Use numpy functions to define abs_diff_numpy and abs_diff_gradient_numpy\n",
        "- Do NOT use functions in linear_algebra.py\n",
        "### <span style=\"color:red\">**Each function must have ONE line of code; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1tlqogG6tzu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# YOUR CODE MUST BE HERE\n",
        "def abs_diff_numpy(x, X):\n",
        "    return np.sum(np.abs(X - x), axis=1).sum()\n",
        "\n",
        "def abs_diff_gradient_numpy(x, X):\n",
        "    return -np.sum(np.sign(X - x), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSRdpwQl6tzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbf024c-f804-407e-e32e-2db7bc0117d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.24 ms, sys: 0 ns, total: 4.24 ms\n",
            "Wall time: 7.38 ms\n",
            "[99.25999999999999, 99.34199999999998]\n",
            "++++++++++ Problem 4 check passed ++++++++++\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "np.random.seed(0)\n",
        "# c = np.array([100,700])\n",
        "# X = c + np.random.randn(100,2)\n",
        "c1 = np.array([100,100])\n",
        "X1 = c1 + np.random.randn(100,2)\n",
        "c2 = np.array([100,0])\n",
        "X2 = c2 + np.random.randn(100,2)\n",
        "c3 = np.array([0,100])\n",
        "X3 = c3 + np.random.randn(100,2)\n",
        "X  = np.vstack((X1, X2, X3))\n",
        "\n",
        "f = partial(abs_diff_numpy, X=X)\n",
        "gradient_f = partial(abs_diff_gradient_numpy, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "%time solution = minimize_batch(f, gradient_f, init_x)\n",
        "\n",
        "### correctness check\n",
        "print(solution)\n",
        "EPSILON = 1\n",
        "cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "cond2 = math.fabs(solution[1] - 100.0) <= EPSILON\n",
        "assert  all([cond1, cond2]), '-'*10 + ' Problem 4 check failed ' + '-'*10\n",
        "print('+'*10 + ' Problem 4 check passed ' + '+'*10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKWeHJT86tzu"
      },
      "source": [
        "## Problem 5 (15 pts)\n",
        "\n",
        "- We want to rewrite ```minimize_batch```.\n",
        "- Do NOT use ```step``` function; provide numpy style code using broadcasting\n",
        "    - Do NOT use ```[step(theta, gradient, -step_size) for step_size in step_sizes]```\n",
        "- Modify ```minimize_batch``` to take ```step_sizes``` as an argument\n",
        "- Modify ```minimize_batch``` to take maximum number of epochs as an argument\n",
        "    - epoch is the number of ```while``` loop iterations in the following code.\n",
        "- Modify ```minimize_batch``` to return ```epoch``` together with ```theta```\n",
        "- Modify ```minimize_batch``` to return ```None``` as solution if it does not converge within max_steps\n",
        "- **Use numpy functions to define sq_dist_numpy_1 and sq_dist_gradient_numpy_1**\n",
        "- **Do NOT use functions in linear_algebra.py**\n",
        "- If all done, now you have an enhanced numpy version of minimize_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T04kLg_26tzu"
      },
      "source": [
        "The following is ```minimize_batch``` in our textbook\n",
        "```python\n",
        "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
        "    \"\"\"use gradient descent to find theta that minimizes target function\"\"\"\n",
        "\n",
        "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "\n",
        "    theta = theta_0                           # set theta to initial value\n",
        "    target_fn = safe(target_fn)               # safe version of target_fn\n",
        "    value = target_fn(theta)                  # value we're minimizing\n",
        "\n",
        "    while True:\n",
        "        gradient = gradient_fn(theta)\n",
        "        next_thetas = [step(theta, gradient, -step_size)\n",
        "                       for step_size in step_sizes]\n",
        "\n",
        "        # choose the one that minimizes the error function\n",
        "        next_theta = min(next_thetas, key=target_fn)\n",
        "        next_value = target_fn(next_theta)\n",
        "\n",
        "        # stop if we're \"converging\"\n",
        "        if abs(value - next_value) < tolerance:\n",
        "            return theta\n",
        "        else:\n",
        "            theta, value = next_theta, next_value\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inpwLIwf6tzu"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n",
        "\n",
        "def minimize_batch_enhanced(target_fn, gradient_fn, theta_0, step_sizes, max_steps=10000, tolerance=0.000001):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXPh8a3q6tzv"
      },
      "source": [
        "### <span style=\"color:red\">**Each function must have ONE line of code; Otherwise, you get zero point (0점)**</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhMBVKTA6tzv"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE MUST BE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25KtX_Yt6tzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23601a6-e7f9-41f4-fb06-b272bc9058fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "<ipython-input-3-496336d5422a>:3: RuntimeWarning: overflow encountered in square\n",
            "  return np.sum(np.square(X - x)).sum()\n",
            "<ipython-input-2-6c893fe76522>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  if abs(value - next_value) < tolerance:\n",
            "<ipython-input-3-496336d5422a>:6: RuntimeWarning: overflow encountered in multiply\n",
            "  return -2 * np.sum(np.subtract(X, x), axis=0)\n",
            "<ipython-input-2-6c893fe76522>:11: RuntimeWarning: invalid value encountered in subtract\n",
            "  next_thetas = theta - step_sizes[:, None] * gradient[None, :]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does not converge within epoch None\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + 10*np.random.randn(1000,2)\n",
        "\n",
        "f = partial(sq_dist_numpy_1, X=X)\n",
        "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "step_sizes = np.array([0.01])\n",
        "\n",
        "solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
        "### correctness check\n",
        "if solution is None:\n",
        "    print('Does not converge within epoch {}'.format(epoch))\n",
        "else:\n",
        "    print('Solution {} found at epoch {}'.format(solution, epoch))\n",
        "    EPSILON = 1\n",
        "    cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "    cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "    assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
        "    print('Problem 5 check passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y21_E5666tzv"
      },
      "source": [
        "Your solution should be like:\n",
        "```\n",
        "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
        "Problem 5 check passed\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TeL1VFc6tzv"
      },
      "outputs": [],
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "# RUN THIS CELL\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "c = np.array([100,700])\n",
        "X = c + 10*np.random.randn(1000,2)\n",
        "\n",
        "f = partial(sq_dist_numpy_1, X=X)\n",
        "gradient_f = partial(sq_dist_gradient_numpy_1, X=X)\n",
        "init_x = np.array([0.,0.])\n",
        "step_sizes_set = [np.array([10]),\n",
        "                  np.array([0.1]),\n",
        "                  np.array([0.01]),\n",
        "                  np.array([0.001]),\n",
        "                  np.array([0.0001]),\n",
        "                  np.array([0.00001]),\n",
        "                  np.array(np.logspace(-3,3,7))\n",
        "                 ]\n",
        "\n",
        "for step_sizes in step_sizes_set:\n",
        "    print()\n",
        "    print('+'*10 + ' Test case {} '.format(step_sizes) + '+'*10)\n",
        "    solution, epoch = minimize_batch_enhanced(f, gradient_f, init_x, step_sizes)\n",
        "    ### correctness check\n",
        "    if solution is None:\n",
        "        print('Does not converge within epoch {}'.format(epoch))\n",
        "    else:\n",
        "        print('Solution {} found at epoch {}'.format(solution, epoch))\n",
        "        EPSILON = 1\n",
        "        cond1 = math.fabs(solution[0] - 100.0) <= EPSILON\n",
        "        cond2 = math.fabs(solution[1] - 700.0) <= EPSILON\n",
        "        assert  all([cond1, cond2]), 'Problem 5 check failed'\n",
        "        print('Problem 5 check passed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzw-sPOL6tzw"
      },
      "source": [
        "Your solution should be like:\n",
        "```\n",
        "++++++++++ Test case [10] ++++++++++\n",
        "...\n",
        "Numpy overflow warning\n",
        "...\n",
        "Does not converge within epoch 10000\n",
        "\n",
        "++++++++++ Test case [0.1] ++++++++++\n",
        "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
        "Problem 5 check passed\n",
        "\n",
        "++++++++++ Test case [0.01] ++++++++++\n",
        "Solution [ 99.78192923 699.8960156 ] found at epoch 587\n",
        "Problem 5 check passed\n",
        "\n",
        "++++++++++ Test case [0.001] ++++++++++\n",
        "Solution [ 99.78040508 699.88532482] found at epoch 5349\n",
        "Problem 5 check passed\n",
        "\n",
        "++++++++++ Test case [0.0001] ++++++++++\n",
        "Does not converge within epoch 10000\n",
        "\n",
        "++++++++++ Test case [1.e-05] ++++++++++\n",
        "Does not converge within epoch 10000\n",
        "\n",
        "++++++++++ Test case [1.e-03 1.e-02 1.e-01 1.e+00 1.e+01 1.e+02 1.e+03] ++++++++++\n",
        "Solution [ 99.78244401 699.89962643] found at epoch 59\n",
        "Problem 5 check passed\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj2pku4Q6tzw"
      },
      "source": [
        "### Double click this cell to edit:\n",
        "\n",
        "What is your conclusion from experiments with the above several test cases?\n",
        "```\n",
        "Write here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5F09fxc6tzw"
      },
      "source": [
        "## Ethics:\n",
        "If you cheat, you will get negatgive of the total points.\n",
        "If the homework total is 22 and you cheat, you get -22."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MK7Nf_66tzx"
      },
      "source": [
        "## What to submit\n",
        "\n",
        "- Run **all cells** after restarting the kernel\n",
        "- Goto \"File -> Print Preview\"\n",
        "- Print the page as pdf\n",
        "- Pdf file name must be in a form of: homework_3_홍길동_202300001.pdf\n",
        "- Submit the pdf file in google classroom\n",
        "- No late homeworks will be accepted\n",
        "- Your homework will be graded on the basis of correctness, performance, and programming skills"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}