{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxGvTQfgs6V2"
      },
      "source": [
        "# Homework 5. KNN - Handwritten digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6sKotsms6V9"
      },
      "source": [
        "***Double Click here to edit this cell***\n",
        "\n",
        "- Name: 김현동\n",
        "- Student ID: 201901208\n",
        "- Submission date: 2023-06-09"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4T4ZV96s6V_"
      },
      "source": [
        "### We have 1797 handwritten digits of size 8x8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXQKR0u9s6WA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d302b881-2345-4d38-9379-5b9cf039ed8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI-cIEA3s6WC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e011a60-577b-4a47-acc5-161bc2330914"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797,)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "digits.target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCMmT6SRs6WD"
      },
      "outputs": [],
      "source": [
        "# Do not run this cell when you submit you homework\n",
        "%%capture\n",
        "print(digits.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tUcg6w8s6WE"
      },
      "source": [
        "### Try with some handwritten images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "EiA0qbZOs6WE"
      },
      "outputs": [],
      "source": [
        "# Do not run this cell when you submit you homework\n",
        "%%capture\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "k = 100\n",
        "print('Target is {}'.format(digits.target[k]))\n",
        "print('Data is :\\n')\n",
        "print(digits.data[k].reshape(8,8))\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[k])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-bNVz-us6WG"
      },
      "source": [
        "### 주의: `train_test_split`의 `random_state`를 0이 아닌 다른 값으로 바꾸거나, 다시 데이터셋을 split하면 0점 처리됨\n",
        "\n",
        "- you must set \"random_state=0\"\" in \"train_test_split\"\n",
        "- don't modify the random number seed (random_state)\n",
        "- Split the data into training dataset (0.67 of the total data), test dataset(0.33 of the total data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qul8DJXps6WH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.33, \\\n",
        "                                                    random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xas-Cvevs6WI"
      },
      "source": [
        "# Problem 1 (10 pts)\n",
        "\n",
        "- We want to classify handwritten digits using **1 nearest neighbor classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgkmdlZvs6WI"
      },
      "source": [
        "## STEP 1\n",
        "\n",
        "- import whatever you need\n",
        "- Use sklearn 1 nearest neighbor classifier to classify digits\n",
        "- Print confusion matrix, classification report, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbTG4oeTs6WJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae862c2d-5034-4432-991f-c74c85416507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix : \n",
            "\n",
            "[[49  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 61  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 62  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 55  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 50  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 63  1  0  0  1]\n",
            " [ 0  0  0  0  0  0 67  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 56  0  0]\n",
            " [ 0  2  0  1  0  0  0  0 64  0]\n",
            " [ 0  0  0  3  0  1  0  0  0 58]]\n",
            "\n",
            "\n",
            "classification_report : \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        49\n",
            "           1       0.97      1.00      0.98        61\n",
            "           2       1.00      1.00      1.00        62\n",
            "           3       0.93      1.00      0.96        55\n",
            "           4       1.00      1.00      1.00        50\n",
            "           5       0.98      0.97      0.98        65\n",
            "           6       0.99      1.00      0.99        67\n",
            "           7       1.00      1.00      1.00        56\n",
            "           8       1.00      0.96      0.98        67\n",
            "           9       0.98      0.94      0.96        62\n",
            "\n",
            "    accuracy                           0.98       594\n",
            "   macro avg       0.99      0.99      0.99       594\n",
            "weighted avg       0.99      0.98      0.98       594\n",
            "\n",
            "Average accuracy = 98.48%\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "cr = classification_report(y_test,y_pred)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print('confusion matrix : \\n')\n",
        "print(cm)\n",
        "print('\\n\\nclassification_report : \\n')\n",
        "print(cr)\n",
        "print('Average accuracy = {:.2f}%'.format(accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd55NIjHs6WJ"
      },
      "source": [
        "My result:\n",
        "```\n",
        "confusion matrix :\n",
        "\n",
        "[[49  0  0  0  0  0  0  0  0  0]\n",
        " [ 0 61  0  0  0  0  0  0  0  0]\n",
        " [ 0  0 62  0  0  0  0  0  0  0]\n",
        " [ 0  0  0 55  0  0  0  0  0  0]\n",
        " [ 0  0  0  0 50  0  0  0  0  0]\n",
        " [ 0  0  0  0  0 63  1  0  0  1]\n",
        " [ 0  0  0  0  0  0 67  0  0  0]\n",
        " [ 0  0  0  0  0  0  0 56  0  0]\n",
        " [ 0  2  0  1  0  0  0  0 64  0]\n",
        " [ 0  0  0  3  0  1  0  0  0 58]]\n",
        "\n",
        "\n",
        "classification_report :\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00        49\n",
        "           1       0.97      1.00      0.98        61\n",
        "           2       1.00      1.00      1.00        62\n",
        "           3       0.93      1.00      0.96        55\n",
        "           4       1.00      1.00      1.00        50\n",
        "           5       0.98      0.97      0.98        65\n",
        "           6       0.99      1.00      0.99        67\n",
        "           7       1.00      1.00      1.00        56\n",
        "           8       1.00      0.96      0.98        67\n",
        "           9       0.98      0.94      0.96        62\n",
        "\n",
        "    accuracy                           0.98       594\n",
        "   macro avg       0.99      0.99      0.99       594\n",
        "weighted avg       0.99      0.98      0.98       594\n",
        "\n",
        "Average accuracy = 98.48%\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC4zDHdRs6WK"
      },
      "source": [
        "# Problem 2 (30 pts) - Choose k\n",
        "\n",
        "- We want to classify handwritten digits using k nearest neighbor classifier\n",
        "- Use dimensionality reduction technique like PCA or TSNE if necessary\n",
        "- If you choose any hyperparameters and you did any transformation in your data, justify your choice and transformation.\n",
        "- The justification must be code, data, or plotted images, **not your guess!!!**\n",
        "- This must be a longer code.\n",
        "- To justify your choice of hyperparameters, use visualization or plotting whenever possible.\n",
        "- You may add as many cells as you want.\n",
        "- To add a cell, insert->insert cell or click '+' button above in the notebook.\n",
        "- you must set \"random_state=0\"\" in \"train_test_split\", \"TSNE\" or on any functions based on random numbers\n",
        "\n",
        "### This will be evaluated based on average accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADD YOUR CELL\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "for i in range(1,10,3):\n",
        "  pca = PCA(n_components=i, random_state=0)\n",
        "  X_train_pca = pca.fit_transform(X_train)\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "\n",
        "  knn = KNeighborsClassifier(n_neighbors=4)\n",
        "  knn.fit(X_train_pca,y_train)\n",
        "\n",
        "  y_pred = knn.predict(X_test_pca)\n",
        "\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "  print(f\"n={i}일때의 수치\\n\")\n",
        "  print('Average Accuracy = {:.2f}%\\n'.format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djaaa2VeYRWO",
        "outputId": "4258d55c-b96e-497a-c53c-a348103ba17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n=1일때의 수치\n",
            "\n",
            "Average Accuracy = 29.46%\n",
            "\n",
            "n=4일때의 수치\n",
            "\n",
            "Average Accuracy = 85.19%\n",
            "\n",
            "n=7일때의 수치\n",
            "\n",
            "Average Accuracy = 96.30%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypkC1c5Ts6WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcca01db-d062-4fce-e35d-c785bcb25f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=1일때의 수치\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        49\n",
            "           1       0.98      0.95      0.97        61\n",
            "           2       0.98      0.98      0.98        62\n",
            "           3       0.88      0.96      0.92        55\n",
            "           4       0.96      1.00      0.98        50\n",
            "           5       0.95      0.95      0.95        65\n",
            "           6       0.96      1.00      0.98        67\n",
            "           7       0.96      0.98      0.97        56\n",
            "           8       0.97      0.90      0.93        67\n",
            "           9       0.95      0.89      0.92        62\n",
            "\n",
            "    accuracy                           0.96       594\n",
            "   macro avg       0.96      0.96      0.96       594\n",
            "weighted avg       0.96      0.96      0.96       594\n",
            "\n",
            "Average Accuracy = 95.96%\n",
            "\n",
            "k=4일때의 수치\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        49\n",
            "           1       0.95      0.98      0.97        61\n",
            "           2       1.00      0.98      0.99        62\n",
            "           3       0.90      0.98      0.94        55\n",
            "           4       0.98      0.98      0.98        50\n",
            "           5       0.97      0.95      0.96        65\n",
            "           6       0.97      0.99      0.98        67\n",
            "           7       0.93      1.00      0.97        56\n",
            "           8       0.95      0.90      0.92        67\n",
            "           9       0.98      0.89      0.93        62\n",
            "\n",
            "    accuracy                           0.96       594\n",
            "   macro avg       0.96      0.97      0.96       594\n",
            "weighted avg       0.96      0.96      0.96       594\n",
            "\n",
            "Average Accuracy = 96.30%\n",
            "\n",
            "k=7일때의 수치\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        49\n",
            "           1       0.95      0.98      0.97        61\n",
            "           2       1.00      0.97      0.98        62\n",
            "           3       0.88      0.93      0.90        55\n",
            "           4       0.98      0.98      0.98        50\n",
            "           5       0.95      0.94      0.95        65\n",
            "           6       0.99      0.99      0.99        67\n",
            "           7       0.95      1.00      0.97        56\n",
            "           8       0.97      0.88      0.92        67\n",
            "           9       0.90      0.90      0.90        62\n",
            "\n",
            "    accuracy                           0.95       594\n",
            "   macro avg       0.95      0.96      0.96       594\n",
            "weighted avg       0.96      0.95      0.95       594\n",
            "\n",
            "Average Accuracy = 95.45%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ADD YOUR CELL\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=7, random_state=0)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "for i in range(1,10,3):\n",
        "\n",
        "  knn = KNeighborsClassifier(n_neighbors=i)\n",
        "  knn.fit(X_train_pca,y_train)\n",
        "\n",
        "  y_pred = knn.predict(X_test_pca)\n",
        "\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  cr = classification_report(y_test, y_pred)\n",
        "\n",
        "  print(f\"k={i}일때의 수치\\n\")\n",
        "  print('\\nClassification Report:\\n', cr)\n",
        "  print('Average Accuracy = {:.2f}%\\n'.format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoiDVctAs6WM"
      },
      "source": [
        "(To edit, double click this cell)\n",
        "### Write your justicaition of your experiment\n",
        "특정 범위의 k 값에 대해 실험을 수행하여 어떤 k 값들이 좋은 성능을 나타내는지 확인했습니다. 좋은 성능의 기준은 Average Accuracy의 값이 높은 것입니다. 이를 위해 k값의 범위를 큰 값에서부터 작은 값까지 조정했습니다.\n",
        "\n",
        "precision , recall , f1-score을 나타낸 Classification Report를 보고 k별 성능차이를 한눈에 파악하기 어려웠습니다. 따라서 전체 샘플을 대상으로 한 정확도 accuracy가 높을수록 성능이 좋다는 판단기준을 세웠습니다.\n",
        "\n",
        "k=1일때 95.96%으로 시작해서 k=10까지 증가함에 따라 일반적으로 94~95%의 성능을 보여줍니다. k=4 일때 96.30%로 가장 높은 성능을 보여줍니다.\n",
        "\n",
        "또한 n_neighbors의 k값 test하기 전, 차원축소 통해 가장 높은 성능을 보이는 n 값을 찾았습니다. 값이 작을수록 더 큰 정보 손실이 발생하지만 계산 비용이 감소하며, 값이 클수록 더 많은 정보를 보존하고 계산 비용이 증가합니다. 현재 데이터셋에서는 n=7일때 가장 높은 효율을 가진다는 것을 실험(코드 실행)을 통해 검증했습니다.\n",
        "\n",
        "(제출은 3개의 샘플만을 추출하여 보여줍니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74uWraDvs6WM"
      },
      "source": [
        "(To edit, double click this cell)\n",
        "\n",
        "### Write your final accuracy in Problem 2:  (just numbers here)\n",
        "\n",
        "96.30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBs2Juszs6WM"
      },
      "source": [
        "# Problem 3 (30 pts) - Other Classifiers\n",
        "\n",
        "- You may use the following classification technique in sklearn:\n",
        "  - Logistic Regression\n",
        "  - Decision Trees\n",
        "  - Support Vector Machines (SVM)\n",
        "  - Naive Bayes\n",
        "  - Perceptron\n",
        "- We want to classify handwritten digits using a classifier in sklearn\n",
        "- Use any feature selection technique\n",
        "- If you choose any hyperparameters and you did any transformation in your data, justify your choice and transformation.\n",
        "- The justification must be code, data, or plotted images, **not your guess!!!**\n",
        "- This must be a longer code.\n",
        "- To justify your choice of hyperparameters, use visualization or plotting whenever possible.\n",
        "- You may add as many cells as you want.\n",
        "- To add a cell, insert->insert cell or click '+' button above in the notebook.\n",
        "- you must set \"random_state=0\"\" in \"train_test_split\", \"TSNE\" or on any functions based on random numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXg7fZYts6WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95697778-03c4-4f3e-950d-941a1dda30d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 93.43434343434343\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[49  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 54  1  0  0  0  2  0  3  1]\n",
            " [ 0  3 58  1  0  0  0  0  0  0]\n",
            " [ 0  0  1 53  0  0  0  0  1  0]\n",
            " [ 0  0  0  0 50  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 63  1  0  0  1]\n",
            " [ 0  1  0  0  0  0 66  0  0  0]\n",
            " [ 0  0  0  0  2  1  0 52  0  1]\n",
            " [ 0  7  1  3  1  0  0  0 54  1]\n",
            " [ 0  0  0  2  0  1  0  1  2 56]]\n"
          ]
        }
      ],
      "source": [
        "# ADD YOUR CELL\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# Feature selection using RFE\n",
        "estimator = LogisticRegression(solver='liblinear', random_state=0)\n",
        "selector = RFE(estimator, n_features_to_select=30, step=1)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Logistic Regression classifier\n",
        "lr = LogisticRegression(solver='liblinear', random_state=0)\n",
        "lr.fit(X_train_selected, y_train)\n",
        "y_pred_lr = lr.predict(X_test_selected)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "# Print the evaluation metrics for each classifier\n",
        "print('Logistic Regression Accuracy:', accuracy_lr*100)\n",
        "print('Logistic Regression Confusion Matrix:\\n', cm_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3g3_xyHs6WO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c9cbe1-e00c-40ac-cdc6-749b7a97f37f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 84.34343434343434\n",
            "Decision Tree Confusion Matrix:\n",
            " [[46  0  0  0  1  0  0  0  0  2]\n",
            " [ 0 51  2  1  2  0  0  0  2  3]\n",
            " [ 1  6 46  1  0  1  1  2  2  2]\n",
            " [ 0  2  0 48  0  0  1  1  2  1]\n",
            " [ 1  0  0  1 45  0  0  2  1  0]\n",
            " [ 0  0  1  1  2 56  1  1  2  1]\n",
            " [ 0  0  0  0  1  1 65  0  0  0]\n",
            " [ 0  0  1  0  0  0  0 52  1  2]\n",
            " [ 1  4  0  7  1  2  0  1 42  9]\n",
            " [ 0  1  2  3  0  3  0  2  1 50]]\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=0)\n",
        "dt.fit(X_train_selected, y_train)\n",
        "y_pred_dt = dt.predict(X_test_selected)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "print('Decision Tree Accuracy:', accuracy_dt*100)\n",
        "print('Decision Tree Confusion Matrix:\\n', cm_dt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machines (SVM) classifier\n",
        "svm = SVC(kernel='linear', random_state=0)\n",
        "svm.fit(X_train_selected, y_train)\n",
        "y_pred_svm = svm.predict(X_test_selected)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print('SVM Accuracy:', accuracy_svm*100)\n",
        "print('SVM Confusion Matrix:\\n', cm_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqVk_dhSQeNp",
        "outputId": "af98ac2e-9a81-4d70-90e9-da0895c99c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 95.1178451178451\n",
            "SVM Confusion Matrix:\n",
            " [[49  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  1  0  3  0]\n",
            " [ 0  2 59  1  0  0  0  0  0  0]\n",
            " [ 0  0  2 53  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 50  0  0  0  0  0]\n",
            " [ 0  0  0  1  0 62  1  0  0  1]\n",
            " [ 0  1  0  0  0  0 66  0  0  0]\n",
            " [ 0  0  0  0  1  1  0 54  0  0]\n",
            " [ 0  5  1  0  1  1  0  0 57  2]\n",
            " [ 0  0  0  3  0  1  0  0  0 58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes classifier\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_selected, y_train)\n",
        "y_pred_nb = nb.predict(X_test_selected)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "\n",
        "print('Naive Bayes Accuracy:', accuracy_nb*100)\n",
        "print('Naive Bayes Confusion Matrix:\\n', cm_nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYaU8El_QeU8",
        "outputId": "b28064c8-494a-4de9-e934-0e3d83f318f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 82.15488215488216\n",
            "Naive Bayes Confusion Matrix:\n",
            " [[49  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 40  4  0  5  1  0  3  6  2]\n",
            " [ 0  3 49  0  0  0  0  0 10  0]\n",
            " [ 0  0  1 40  0  0  0  2  7  5]\n",
            " [ 0  0  0  0 42  0  0  8  0  0]\n",
            " [ 0  0  0  0  1 53  1  9  0  1]\n",
            " [ 0  1  0  0  0  1 65  0  0  0]\n",
            " [ 0  0  0  0  2  0  0 54  0  0]\n",
            " [ 0  3  0  3  3  0  0  7 51  0]\n",
            " [ 0  0  0  5  1  0  0  5  6 45]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron classifier\n",
        "perceptron = Perceptron(random_state=0)\n",
        "perceptron.fit(X_train_selected, y_train)\n",
        "y_pred_perceptron = perceptron.predict(X_test_selected)\n",
        "accuracy_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
        "cm_perceptron = confusion_matrix(y_test, y_pred_perceptron)\n",
        "\n",
        "print('Perceptron Accuracy:', accuracy_perceptron*100)\n",
        "print('Perceptron Confusion Matrix:\\n', cm_perceptron)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emv-gSDcQed0",
        "outputId": "41099fd0-5995-4143-9dd7-e967a9d14d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron Accuracy: 90.23569023569024\n",
            "Perceptron Confusion Matrix:\n",
            " [[48  0  0  0  0  0  1  0  0  0]\n",
            " [ 0 60  0  0  0  0  0  0  1  0]\n",
            " [ 0  7 55  0  0  0  0  0  0  0]\n",
            " [ 0  0  1 52  0  0  0  0  1  1]\n",
            " [ 0  2  0  0 46  0  0  2  0  0]\n",
            " [ 0  1  0  0  0 62  2  0  0  0]\n",
            " [ 0  1  0  0  0  0 66  0  0  0]\n",
            " [ 0  0  0  0  1  1  0 54  0  0]\n",
            " [ 0 12  3  2  0  0  1  2 47  0]\n",
            " [ 0  6  0  2  0  1  0  2  5 46]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkA0u1lgs6WO"
      },
      "source": [
        "(To edit, double click this cell)\n",
        "### Write your justicaition of your experiment\n",
        "Logistic Regression , Decision Trees , Support Vector Machines (SVM) , Naive Bayes , Perceptron\n",
        "\n",
        "다섯가지 분류 모델을 사용해서 모델별 성능을 테스트를 진행했습니다. 위에서 코드 실행 결과 (Accuracy , Confusion Matrix)를 확인할 수 있습니다.\n",
        "\n",
        "Confusion Matrix를 통해 각 모델이 얼마나 정확한 예측을 했는지, 오분류 됐는지 확인 가능합니다. 비교적 정확한 예측을 진행한 모델은 Logistic Regression , SVM  두가지 입니다. 높은 예측률과 적은 오분류를 보이는만큼 93퍼센트 이상의 높은 정확도를 보입니다. 그 중에서도 SVM에는 95.11%의 가장 높은 정확도를 가짐을 확인 가능합니다.\n",
        "\n",
        "반면에 Decision Trees , Navie Bayes, Perceptron 오분류 샘플이 많이 보이며, 비교적 낮은 성능을 보여줍니다.\n",
        "\n",
        "5가지 모델은 지도학습 모델로, 정답인 label을 포함한 데이터를 학습한다는 점에서 비슷한 성능을 보일 것으로 생각했습니다. 하지만 각 모델별로 큰 성능 차이를 보임을 확인했습니다. 0.1%라는 작은 값이라도 AI 예측에서는 오류를 몇배 줄였다고 판단 가능한만큼 그 차이는 크다고 할 수 있습니다.\n",
        "\n",
        "각 모델은 내부적으로 다른 가정과 알고리즘을 사용하여 데이터를 학습하고 예측합니다. 데이터셋과 문제의 특성에 따라 역전된 결과를 보여줄 수 있습니다. 이러한 결과는 데이터셋에 따른 학습 모델 선택이 중요함을 알게 해줬습니다.\n",
        "\n",
        "\n",
        "------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "로지스틱 회귀 : 입력 데이터의 선형 결합에 로지스틱 함수를 적용하는데, 이 때 각 입력 변수를 그대로 사용할 수도 있고, 다항식이나 상호작용 항 등의 특징을 추가로 생성할 수도 있습니다.\n",
        "\n",
        "의사결정나무 : 특징을 추출하는 대신 데이터를 구분하는 결정 규칙(조건)을 학습합니다. 데이터를 분할하는 기준에 따라 특징이 결정되며, 이는 특징의 중요도나 유용성을 나타내는 역할을 합니다.\n",
        "\n",
        "SVM : 입력 데이터를 고차원 특징 공간으로 매핑하는 커널 함수를 사용하여 데이터를 분류합니다. 이러한 커널 함수를 통해 데이터를 분리하는 최적의 경계를 찾게 되며, 이러한 경계에 따라 특징이 결정됩니다.\n",
        "\n",
        "나이브 베이즈 : 데이터의 특징 간의 독립성 가정을 기반으로 학습되며, 입력 데이터의 각 특징이 주어진 클래스에 대해 조건부로 독립적으로 발생한다고 가정합니다. 이를 통해 특징의 확률 분포를 추정하고 예측을 수행합니다.\n",
        "\n",
        "퍼셉트론 : 입력 데이터와 가중치의 선형 결합에 활성화 함수를 적용하여 출력을 계산합니다. 이때 가중치는 학습을 통해 조정되며, 각 입력 변수와 가중치의 조합에 따라 특징이 결정됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8z5J2ZJs6WO"
      },
      "source": [
        "(To edit, double click this cell)\n",
        "\n",
        "### Write your final best accuracy in Problem 3: (just numbers here)\n",
        "95.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc3B9A2xs6WP"
      },
      "source": [
        "## State-of-the-Art of MNIST classification: 99.79%\n",
        "\n",
        "- https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
        "- MNIST dataset is much bigger dataset: 60,000 training images and 10,000 testing images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg9q-xm-s6WP"
      },
      "source": [
        "## Ethics:\n",
        "If you cheat, you will get negatgive of the total points.\n",
        "If the homework total is 22 and you cheat, you get -22."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWYon0nIs6WP"
      },
      "source": [
        "## What to submit\n",
        "\n",
        "- Run **all cells** after restarting the kernel\n",
        "- Goto \"File -> Print Preview\"\n",
        "- Print the page as pdf\n",
        "- Pdf file name must be in a form of: homework_5_홍길동_202300001.pdf\n",
        "- Submit the pdf file in google classroom\n",
        "- No late homeworks will be accepted\n",
        "- Your homework will be graded on the basis of correctness and programming skills"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}